{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "17d55c63",
   "metadata": {},
   "source": [
    "# An√°lisis de Machine Learning: Predicci√≥n de C√°ncer de Pulm√≥n\n",
    "\n",
    "## Proyecto de clasificaci√≥n binaria para identificar pacientes con riesgo de c√°ncer de pulm√≥n\n",
    "\n",
    "Este notebook implementa un ciclo completo de Machine Learning utilizando el dataset `survey_lung_cancer.csv` de Kaggle. El objetivo es predecir si un paciente tiene c√°ncer de pulm√≥n bas√°ndose en factores personales y cl√≠nicos.\n",
    "\n",
    "### Contexto del Problema:\n",
    "- **Tipo**: Clasificaci√≥n binaria (YES/NO para c√°ncer de pulm√≥n)\n",
    "- **Variables**: Mezcla de categ√≥ricas y num√©ricas\n",
    "- **Objetivo**: Identificar patrones que indiquen riesgo de c√°ncer de pulm√≥n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6afb4cff",
   "metadata": {},
   "source": [
    "## 1. Importaci√≥n de Librer√≠as\n",
    "\n",
    "Importamos todas las librer√≠as necesarias para el an√°lisis, preprocesamiento y modelado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f8a287a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Librer√≠as para manipulaci√≥n de datos\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Librer√≠as para visualizaci√≥n\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Librer√≠as de Machine Learning\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import (accuracy_score, precision_score, recall_score, \n",
    "                           f1_score, confusion_matrix, classification_report, \n",
    "                           roc_curve, auc, roc_auc_score)\n",
    "\n",
    "# Configuraci√≥n de visualizaci√≥n\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "\n",
    "# Suprimir warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"‚úÖ Todas las librer√≠as importadas correctamente\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3928373",
   "metadata": {},
   "source": [
    "## 2. Carga y Exploraci√≥n Inicial del Dataset\n",
    "\n",
    "Cargamos el dataset y realizamos una exploraci√≥n inicial para entender la estructura de los datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afed462e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar el dataset\n",
    "df = pd.read_csv('survey_lung_cancer.csv')\n",
    "\n",
    "print(\"üîç INFORMACI√ìN B√ÅSICA DEL DATASET\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Forma del dataset: {df.shape}\")\n",
    "print(f\"N√∫mero de filas: {df.shape[0]}\")\n",
    "print(f\"N√∫mero de columnas: {df.shape[1]}\")\n",
    "print(\"\\nüìã PRIMERAS 5 FILAS:\")\n",
    "display(df.head())\n",
    "\n",
    "print(\"\\nüìä INFORMACI√ìN GENERAL:\")\n",
    "print(df.info())\n",
    "\n",
    "print(\"\\nüè∑Ô∏è NOMBRES DE LAS COLUMNAS:\")\n",
    "print(df.columns.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db568cb0",
   "metadata": {},
   "source": [
    "## 3. An√°lisis Exploratorio de Datos (EDA)\n",
    "\n",
    "Realizamos un an√°lisis detallado de las caracter√≠sticas del dataset, incluyendo estad√≠sticas descriptivas y identificaci√≥n de tipos de datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5318cf28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Descripci√≥n estad√≠stica de todas las caracter√≠sticas\n",
    "print(\"üìà ESTAD√çSTICAS DESCRIPTIVAS COMPLETAS\")\n",
    "print(\"=\"*60)\n",
    "display(df.describe(include='all'))\n",
    "\n",
    "print(\"\\nüéØ DISTRIBUCI√ìN DE LA VARIABLE OBJETIVO (LUNG_CANCER):\")\n",
    "target_counts = df['LUNG_CANCER'].value_counts()\n",
    "print(target_counts)\n",
    "print(f\"\\nPorcentaje de casos positivos: {target_counts['YES']/len(df)*100:.2f}%\")\n",
    "print(f\"Porcentaje de casos negativos: {target_counts['NO']/len(df)*100:.2f}%\")\n",
    "\n",
    "# Identificar tipos de datos\n",
    "print(\"\\nüîç TIPOS DE DATOS POR COLUMNA:\")\n",
    "for col in df.columns:\n",
    "    unique_vals = df[col].nunique()\n",
    "    print(f\"{col}: {df[col].dtype} (valores √∫nicos: {unique_vals})\")\n",
    "    if unique_vals <= 10:  # Mostrar valores √∫nicos para columnas categ√≥ricas\n",
    "        print(f\"  ‚Üí Valores: {sorted(df[col].unique())}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7d843a2",
   "metadata": {},
   "source": [
    "## 4. Detecci√≥n y An√°lisis de Valores Faltantes\n",
    "\n",
    "Analizamos si existen valores faltantes en el dataset y creamos visualizaciones para entender los patrones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eb69b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detectar valores faltantes\n",
    "print(\"üïµÔ∏è AN√ÅLISIS DE VALORES FALTANTES\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "missing_data = df.isnull().sum()\n",
    "missing_percent = (missing_data / len(df)) * 100\n",
    "\n",
    "missing_info = pd.DataFrame({\n",
    "    'Columna': missing_data.index,\n",
    "    'Valores Faltantes': missing_data.values,\n",
    "    'Porcentaje (%)': missing_percent.values\n",
    "}).sort_values('Valores Faltantes', ascending=False)\n",
    "\n",
    "print(\"üìä RESUMEN DE VALORES FALTANTES:\")\n",
    "display(missing_info)\n",
    "\n",
    "if missing_data.sum() == 0:\n",
    "    print(\"‚úÖ ¬°Excelente! No hay valores faltantes en el dataset.\")\n",
    "else:\n",
    "    # Crear visualizaci√≥n de valores faltantes\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
    "    \n",
    "    # Mapa de calor de valores faltantes\n",
    "    sns.heatmap(df.isnull(), yticklabels=False, cbar=True, cmap='viridis', ax=axes[0])\n",
    "    axes[0].set_title('Mapa de Calor - Valores Faltantes', fontsize=14)\n",
    "    \n",
    "    # Gr√°fico de barras de valores faltantes\n",
    "    missing_cols = missing_info[missing_info['Valores Faltantes'] > 0]\n",
    "    if not missing_cols.empty:\n",
    "        sns.barplot(data=missing_cols, x='Valores Faltantes', y='Columna', ax=axes[1])\n",
    "        axes[1].set_title('Cantidad de Valores Faltantes por Columna', fontsize=14)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41db0a4f",
   "metadata": {},
   "source": [
    "## 5. An√°lisis de Distribuciones\n",
    "\n",
    "Analizamos las distribuciones de las caracter√≠sticas num√©ricas y categ√≥ricas para entender mejor los datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f4ab70f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identificar columnas num√©ricas y categ√≥ricas\n",
    "numeric_cols = ['AGE']  # Solo AGE es verdaderamente num√©rica\n",
    "categorical_cols = [col for col in df.columns if col not in ['AGE', 'LUNG_CANCER']]\n",
    "\n",
    "print(\"üìä AN√ÅLISIS DE DISTRIBUCIONES\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Columnas num√©ricas: {numeric_cols}\")\n",
    "print(f\"Columnas categ√≥ricas: {categorical_cols}\")\n",
    "\n",
    "# 1. An√°lisis de caracter√≠sticas num√©ricas (AGE)\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Histograma de edad\n",
    "axes[0].hist(df['AGE'], bins=20, edgecolor='black', alpha=0.7)\n",
    "axes[0].set_title('Distribuci√≥n de Edad', fontsize=14)\n",
    "axes[0].set_xlabel('Edad')\n",
    "axes[0].set_ylabel('Frecuencia')\n",
    "\n",
    "# Boxplot de edad\n",
    "sns.boxplot(y=df['AGE'], ax=axes[1])\n",
    "axes[1].set_title('Boxplot de Edad', fontsize=14)\n",
    "axes[1].set_ylabel('Edad')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Estad√≠sticas de edad por grupo de c√°ncer\n",
    "print(\"\\nüìà ESTAD√çSTICAS DE EDAD POR GRUPO:\")\n",
    "age_stats = df.groupby('LUNG_CANCER')['AGE'].describe()\n",
    "display(age_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6875b00f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. An√°lisis de caracter√≠sticas categ√≥ricas\n",
    "print(\"\\nüìä AN√ÅLISIS DE VARIABLES CATEG√ìRICAS:\")\n",
    "\n",
    "# Crear subplots para todas las variables categ√≥ricas\n",
    "n_cols = 3\n",
    "n_rows = len(categorical_cols) // n_cols + (1 if len(categorical_cols) % n_cols > 0 else 0)\n",
    "\n",
    "fig, axes = plt.subplots(n_rows, n_cols, figsize=(18, n_rows * 4))\n",
    "axes = axes.flatten() if n_rows > 1 else [axes] if n_rows == 1 else axes\n",
    "\n",
    "for i, col in enumerate(categorical_cols):\n",
    "    if i < len(axes):\n",
    "        value_counts = df[col].value_counts()\n",
    "        axes[i].bar(value_counts.index, value_counts.values)\n",
    "        axes[i].set_title(f'Distribuci√≥n de {col}', fontsize=12)\n",
    "        axes[i].set_xlabel(col)\n",
    "        axes[i].set_ylabel('Frecuencia')\n",
    "        \n",
    "        # Rotar etiquetas si es necesario\n",
    "        if len(str(value_counts.index[0])) > 2:\n",
    "            axes[i].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Ocultar axes vac√≠os\n",
    "for i in range(len(categorical_cols), len(axes)):\n",
    "    axes[i].set_visible(False)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# An√°lisis de la variable objetivo\n",
    "print(\"\\nüéØ DISTRIBUCI√ìN DE LA VARIABLE OBJETIVO:\")\n",
    "target_dist = df['LUNG_CANCER'].value_counts()\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.pie(target_dist.values, labels=target_dist.index, autopct='%1.1f%%', startangle=90)\n",
    "plt.title('Distribuci√≥n de C√°ncer de Pulm√≥n', fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a49524c2",
   "metadata": {},
   "source": [
    "## 6. An√°lisis de Correlaciones\n",
    "\n",
    "Analizamos las correlaciones entre caracter√≠sticas para identificar relaciones importantes con la variable objetivo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e49b09f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para calcular correlaciones, necesitamos convertir variables categ√≥ricas a num√©ricas\n",
    "print(\"üîó AN√ÅLISIS DE CORRELACIONES\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Crear una copia del dataframe para an√°lisis num√©rico\n",
    "df_numeric = df.copy()\n",
    "\n",
    "# Convertir variables categ√≥ricas binarias a num√©ricas\n",
    "df_numeric['LUNG_CANCER'] = df_numeric['LUNG_CANCER'].map({'NO': 0, 'YES': 1})\n",
    "df_numeric['GENDER'] = df_numeric['GENDER'].map({'F': 0, 'M': 1})\n",
    "\n",
    "# Las dem√°s columnas ya est√°n en formato num√©rico (1, 2)\n",
    "print(\"‚úÖ Variables convertidas para an√°lisis de correlaci√≥n\")\n",
    "\n",
    "# Calcular matriz de correlaci√≥n\n",
    "correlation_matrix = df_numeric.corr()\n",
    "\n",
    "# Crear mapa de calor de correlaciones\n",
    "plt.figure(figsize=(14, 10))\n",
    "sns.heatmap(correlation_matrix, \n",
    "            annot=True, \n",
    "            cmap='RdBu_r', \n",
    "            center=0,\n",
    "            square=True,\n",
    "            fmt='.2f',\n",
    "            cbar_kws={'shrink': 0.8})\n",
    "plt.title('Mapa de Calor - Matriz de Correlaci√≥n', fontsize=16)\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.yticks(rotation=0)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Correlaciones con la variable objetivo\n",
    "target_correlations = correlation_matrix['LUNG_CANCER'].sort_values(key=abs, ascending=False)\n",
    "print(\"\\nüéØ CORRELACIONES CON LA VARIABLE OBJETIVO (LUNG_CANCER):\")\n",
    "print(\"=\"*60)\n",
    "for feature, corr in target_correlations.items():\n",
    "    if feature != 'LUNG_CANCER':\n",
    "        print(f\"{feature:25} : {corr:6.3f}\")\n",
    "        \n",
    "print(\"\\nüìä TOP 5 CARACTER√çSTICAS M√ÅS CORRELACIONADAS:\")\n",
    "top_features = target_correlations[1:6]  # Excluir la variable objetivo\n",
    "for feature, corr in top_features.items():\n",
    "    print(f\"‚Ä¢ {feature}: {corr:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "817306b8",
   "metadata": {},
   "source": [
    "## 7. Preprocesamiento de Datos\n",
    "\n",
    "Implementamos las estrategias de preprocesamiento necesarias antes del entrenamiento de los modelos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdba78a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocesamiento de datos\n",
    "print(\"üõ†Ô∏è PREPROCESAMIENTO DE DATOS\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# 1. Manejo de valores faltantes\n",
    "print(\"1Ô∏è‚É£ MANEJO DE VALORES FALTANTES:\")\n",
    "if df.isnull().sum().sum() == 0:\n",
    "    print(\"‚úÖ No se requiere manejo de valores faltantes - el dataset est√° completo\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Se requiere manejo de valores faltantes\")\n",
    "    # Aqu√≠ implementar√≠as la estrategia seg√∫n el caso\n",
    "\n",
    "# 2. Crear dataset para el modelo\n",
    "df_model = df.copy()\n",
    "\n",
    "print(\"\\n2Ô∏è‚É£ CODIFICACI√ìN DE VARIABLES CATEG√ìRICAS:\")\n",
    "print(\"üìã Estrategia elegida: Label Encoding\")\n",
    "print(\"üí° Justificaci√≥n: Las variables categ√≥ricas son binarias o ordinales,\")\n",
    "print(\"   Label Encoding es suficiente y m√°s eficiente que One-Hot Encoding\")\n",
    "\n",
    "# Aplicar Label Encoding\n",
    "label_encoders = {}\n",
    "\n",
    "# Codificar GENDER\n",
    "label_encoders['GENDER'] = LabelEncoder()\n",
    "df_model['GENDER'] = label_encoders['GENDER'].fit_transform(df_model['GENDER'])\n",
    "\n",
    "# Codificar variable objetivo\n",
    "label_encoders['LUNG_CANCER'] = LabelEncoder()\n",
    "df_model['LUNG_CANCER'] = label_encoders['LUNG_CANCER'].fit_transform(df_model['LUNG_CANCER'])\n",
    "\n",
    "print(f\"‚úÖ GENDER codificado: {dict(zip(label_encoders['GENDER'].classes_, label_encoders['GENDER'].transform(label_encoders['GENDER'].classes_)))}\")\n",
    "print(f\"‚úÖ LUNG_CANCER codificado: {dict(zip(label_encoders['LUNG_CANCER'].classes_, label_encoders['LUNG_CANCER'].transform(label_encoders['LUNG_CANCER'].classes_)))}\")\n",
    "\n",
    "# Las dem√°s variables ya est√°n en formato num√©rico (1, 2)\n",
    "print(\"‚úÖ Otras variables ya est√°n en formato num√©rico\")\n",
    "\n",
    "print(\"\\nüìä DATASET PROCESADO:\")\n",
    "display(df_model.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a30c80ce",
   "metadata": {},
   "source": [
    "## 8. Escalado de Caracter√≠sticas y Divisi√≥n del Dataset\n",
    "\n",
    "Aplicamos escalado a las caracter√≠sticas num√©ricas y dividimos el dataset en conjuntos de entrenamiento y prueba."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "677f2950",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Escalado de caracter√≠sticas\n",
    "print(\"3Ô∏è‚É£ ESCALADO DE CARACTER√çSTICAS:\")\n",
    "print(\"üìã Estrategia elegida: StandardScaler\")\n",
    "print(\"üí° Justificaci√≥n: La edad tiene una escala diferente a las otras variables\")\n",
    "print(\"   StandardScaler normaliza todas las caracter√≠sticas a media=0 y std=1\")\n",
    "\n",
    "# Definir caracter√≠sticas (X) y variable objetivo (y)\n",
    "X = df_model.drop('LUNG_CANCER', axis=1)\n",
    "y = df_model['LUNG_CANCER']\n",
    "\n",
    "print(f\"\\nüìä FORMA DE LOS DATOS:\")\n",
    "print(f\"Caracter√≠sticas (X): {X.shape}\")\n",
    "print(f\"Variable objetivo (y): {y.shape}\")\n",
    "\n",
    "# 4. Divisi√≥n del dataset\n",
    "print(\"\\n4Ô∏è‚É£ DIVISI√ìN DEL DATASET:\")\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, \n",
    "    test_size=0.2, \n",
    "    random_state=42, \n",
    "    stratify=y  # Mantener la proporci√≥n de clases\n",
    ")\n",
    "\n",
    "print(f\"‚úÖ Conjunto de entrenamiento: {X_train.shape[0]} muestras\")\n",
    "print(f\"‚úÖ Conjunto de prueba: {X_test.shape[0]} muestras\")\n",
    "print(f\"‚úÖ Proporci√≥n de divisi√≥n: 80% entrenamiento, 20% prueba\")\n",
    "\n",
    "# Verificar distribuci√≥n de clases\n",
    "print(\"\\nüìä DISTRIBUCI√ìN DE CLASES:\")\n",
    "print(\"Entrenamiento:\", y_train.value_counts().sort_index())\n",
    "print(\"Prueba:\", y_test.value_counts().sort_index())\n",
    "\n",
    "# 5. Aplicar escalado\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(\"\\n‚úÖ Escalado aplicado correctamente\")\n",
    "print(f\"Media de caracter√≠sticas en entrenamiento: {X_train_scaled.mean(axis=0).round(3)}\")\n",
    "print(f\"Desviaci√≥n est√°ndar en entrenamiento: {X_train_scaled.std(axis=0).round(3)}\")\n",
    "\n",
    "# Convertir de vuelta a DataFrame para facilidad de uso\n",
    "X_train_scaled = pd.DataFrame(X_train_scaled, columns=X.columns)\n",
    "X_test_scaled = pd.DataFrame(X_test_scaled, columns=X.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0caee40c",
   "metadata": {},
   "source": [
    "## 9. Modelo 1: Regresi√≥n Log√≠stica\n",
    "\n",
    "Implementamos y entrenamos un modelo de Regresi√≥n Log√≠stica para la clasificaci√≥n binaria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35f4dcf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODELO 1: REGRESI√ìN LOG√çSTICA\n",
    "print(\"ü§ñ MODELO 1: REGRESI√ìN LOG√çSTICA\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Crear y entrenar el modelo\n",
    "lr_model = LogisticRegression(random_state=42, max_iter=1000)\n",
    "lr_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Realizar predicciones\n",
    "y_pred_lr = lr_model.predict(X_test_scaled)\n",
    "y_pred_proba_lr = lr_model.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "# Calcular m√©tricas\n",
    "lr_accuracy = accuracy_score(y_test, y_pred_lr)\n",
    "lr_precision = precision_score(y_test, y_pred_lr)\n",
    "lr_recall = recall_score(y_test, y_pred_lr)\n",
    "lr_f1 = f1_score(y_test, y_pred_lr)\n",
    "lr_auc = roc_auc_score(y_test, y_pred_proba_lr)\n",
    "\n",
    "print(\"üìä RESULTADOS DEL MODELO:\")\n",
    "print(f\"‚úÖ Accuracy:  {lr_accuracy:.4f}\")\n",
    "print(f\"‚úÖ Precision: {lr_precision:.4f}\")\n",
    "print(f\"‚úÖ Recall:    {lr_recall:.4f}\")\n",
    "print(f\"‚úÖ F1-Score:  {lr_f1:.4f}\")\n",
    "print(f\"‚úÖ AUC-ROC:   {lr_auc:.4f}\")\n",
    "\n",
    "# Matriz de confusi√≥n\n",
    "cm_lr = confusion_matrix(y_test, y_pred_lr)\n",
    "print(f\"\\nüìã MATRIZ DE CONFUSI√ìN:\")\n",
    "print(cm_lr)\n",
    "\n",
    "# Visualizaci√≥n de resultados\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Matriz de confusi√≥n\n",
    "sns.heatmap(cm_lr, annot=True, fmt='d', cmap='Blues', ax=axes[0])\n",
    "axes[0].set_title('Matriz de Confusi√≥n - Regresi√≥n Log√≠stica')\n",
    "axes[0].set_xlabel('Predicci√≥n')\n",
    "axes[0].set_ylabel('Real')\n",
    "\n",
    "# Curva ROC\n",
    "fpr_lr, tpr_lr, _ = roc_curve(y_test, y_pred_proba_lr)\n",
    "axes[1].plot(fpr_lr, tpr_lr, color='darkorange', lw=2, label=f'ROC curve (AUC = {lr_auc:.2f})')\n",
    "axes[1].plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "axes[1].set_xlim([0.0, 1.0])\n",
    "axes[1].set_ylim([0.0, 1.05])\n",
    "axes[1].set_xlabel('Tasa de Falsos Positivos')\n",
    "axes[1].set_ylabel('Tasa de Verdaderos Positivos')\n",
    "axes[1].set_title('Curva ROC - Regresi√≥n Log√≠stica')\n",
    "axes[1].legend(loc=\"lower right\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Reporte de clasificaci√≥n detallado\n",
    "print(\"\\nüìÑ REPORTE DE CLASIFICACI√ìN DETALLADO:\")\n",
    "print(classification_report(y_test, y_pred_lr, target_names=['No Cancer', 'Cancer']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7b7f332",
   "metadata": {},
   "source": [
    "## 10. Modelo 2: K-Vecinos M√°s Cercanos (k-NN)\n",
    "\n",
    "Implementamos y entrenamos un modelo k-NN probando diferentes valores de k."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "131c8d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODELO 2: K-VECINOS M√ÅS CERCANOS (k-NN)\n",
    "print(\"ü§ñ MODELO 2: K-VECINOS M√ÅS CERCANOS (k-NN)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Probar diferentes valores de k\n",
    "k_values = range(3, 21, 2)  # Valores impares de 3 a 19\n",
    "knn_scores = []\n",
    "\n",
    "print(\"üîç PROBANDO DIFERENTES VALORES DE K:\")\n",
    "for k in k_values:\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    knn.fit(X_train_scaled, y_train)\n",
    "    score = knn.score(X_test_scaled, y_test)\n",
    "    knn_scores.append(score)\n",
    "    print(f\"k={k}: Accuracy = {score:.4f}\")\n",
    "\n",
    "# Encontrar el mejor k\n",
    "best_k = k_values[np.argmax(knn_scores)]\n",
    "best_score = max(knn_scores)\n",
    "print(f\"\\nüèÜ MEJOR VALOR DE K: {best_k} (Accuracy: {best_score:.4f})\")\n",
    "\n",
    "# Visualizar performance vs k\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(k_values, knn_scores, 'bo-', linewidth=2, markersize=8)\n",
    "plt.title('Accuracy del Modelo k-NN vs Valor de k', fontsize=14)\n",
    "plt.xlabel('Valor de k')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.axvline(x=best_k, color='red', linestyle='--', alpha=0.7, label=f'Mejor k = {best_k}')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Entrenar modelo con el mejor k\n",
    "knn_model = KNeighborsClassifier(n_neighbors=best_k)\n",
    "knn_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Realizar predicciones\n",
    "y_pred_knn = knn_model.predict(X_test_scaled)\n",
    "y_pred_proba_knn = knn_model.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "# Calcular m√©tricas\n",
    "knn_accuracy = accuracy_score(y_test, y_pred_knn)\n",
    "knn_precision = precision_score(y_test, y_pred_knn)\n",
    "knn_recall = recall_score(y_test, y_pred_knn)\n",
    "knn_f1 = f1_score(y_test, y_pred_knn)\n",
    "knn_auc = roc_auc_score(y_test, y_pred_proba_knn)\n",
    "\n",
    "print(f\"\\nüìä RESULTADOS DEL MODELO (k={best_k}):\")\n",
    "print(f\"‚úÖ Accuracy:  {knn_accuracy:.4f}\")\n",
    "print(f\"‚úÖ Precision: {knn_precision:.4f}\")\n",
    "print(f\"‚úÖ Recall:    {knn_recall:.4f}\")\n",
    "print(f\"‚úÖ F1-Score:  {knn_f1:.4f}\")\n",
    "print(f\"‚úÖ AUC-ROC:   {knn_auc:.4f}\")\n",
    "\n",
    "# Matriz de confusi√≥n\n",
    "cm_knn = confusion_matrix(y_test, y_pred_knn)\n",
    "print(f\"\\nüìã MATRIZ DE CONFUSI√ìN:\")\n",
    "print(cm_knn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f20aa206",
   "metadata": {},
   "source": [
    "## 11. Modelo 3: Random Forest (Bonificaci√≥n)\n",
    "\n",
    "Implementamos un tercer modelo usando Random Forest para mejorar el rendimiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dbb5777",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODELO 3: RANDOM FOREST (BONIFICACI√ìN)\n",
    "print(\"ü§ñ MODELO 3: RANDOM FOREST (BONIFICACI√ìN)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Crear y entrenar el modelo Random Forest\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Realizar predicciones\n",
    "y_pred_rf = rf_model.predict(X_test_scaled)\n",
    "y_pred_proba_rf = rf_model.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "# Calcular m√©tricas\n",
    "rf_accuracy = accuracy_score(y_test, y_pred_rf)\n",
    "rf_precision = precision_score(y_test, y_pred_rf)\n",
    "rf_recall = recall_score(y_test, y_pred_rf)\n",
    "rf_f1 = f1_score(y_test, y_pred_rf)\n",
    "rf_auc = roc_auc_score(y_test, y_pred_proba_rf)\n",
    "\n",
    "print(\"üìä RESULTADOS DEL MODELO:\")\n",
    "print(f\"‚úÖ Accuracy:  {rf_accuracy:.4f}\")\n",
    "print(f\"‚úÖ Precision: {rf_precision:.4f}\")\n",
    "print(f\"‚úÖ Recall:    {rf_recall:.4f}\")\n",
    "print(f\"‚úÖ F1-Score:  {rf_f1:.4f}\")\n",
    "print(f\"‚úÖ AUC-ROC:   {rf_auc:.4f}\")\n",
    "\n",
    "# Importancia de caracter√≠sticas\n",
    "feature_importance = rf_model.feature_importances_\n",
    "feature_names = X.columns\n",
    "\n",
    "# Crear DataFrame para importancia de caracter√≠sticas\n",
    "importance_df = pd.DataFrame({\n",
    "    'Caracter√≠stica': feature_names,\n",
    "    'Importancia': feature_importance\n",
    "}).sort_values('Importancia', ascending=False)\n",
    "\n",
    "print(\"\\nüéØ IMPORTANCIA DE CARACTER√çSTICAS:\")\n",
    "display(importance_df)\n",
    "\n",
    "# Visualizar importancia de caracter√≠sticas\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.barplot(data=importance_df, x='Importancia', y='Caracter√≠stica')\n",
    "plt.title('Importancia de Caracter√≠sticas - Random Forest', fontsize=14)\n",
    "plt.xlabel('Importancia')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Matriz de confusi√≥n\n",
    "cm_rf = confusion_matrix(y_test, y_pred_rf)\n",
    "print(f\"\\nüìã MATRIZ DE CONFUSI√ìN:\")\n",
    "print(cm_rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a77cb828",
   "metadata": {},
   "source": [
    "## 12. Ajuste de Hiperpar√°metros\n",
    "\n",
    "Utilizamos GridSearchCV para optimizar los hiperpar√°metros del modelo de Regresi√≥n Log√≠stica."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "847f2440",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AJUSTE DE HIPERPAR√ÅMETROS\n",
    "print(\"‚öôÔ∏è AJUSTE DE HIPERPAR√ÅMETROS - REGRESI√ìN LOG√çSTICA\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Definir grid de par√°metros para Regresi√≥n Log√≠stica\n",
    "param_grid_lr = {\n",
    "    'C': [0.1, 1, 10, 100],\n",
    "    'penalty': ['l1', 'l2'],\n",
    "    'solver': ['liblinear', 'saga']\n",
    "}\n",
    "\n",
    "print(\"üîç PAR√ÅMETROS A EVALUAR:\")\n",
    "for param, values in param_grid_lr.items():\n",
    "    print(f\"  ‚Ä¢ {param}: {values}\")\n",
    "\n",
    "# Realizar GridSearchCV\n",
    "grid_search_lr = GridSearchCV(\n",
    "    LogisticRegression(random_state=42, max_iter=1000),\n",
    "    param_grid_lr,\n",
    "    cv=5,\n",
    "    scoring='accuracy',\n",
    "    n_jobs=-1,\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "print(f\"\\nüöÄ Ejecutando Grid Search con {5} folds de validaci√≥n cruzada...\")\n",
    "grid_search_lr.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Mejores par√°metros\n",
    "print(f\"\\nüèÜ MEJORES HIPERPAR√ÅMETROS:\")\n",
    "for param, value in grid_search_lr.best_params_.items():\n",
    "    print(f\"  ‚Ä¢ {param}: {value}\")\n",
    "\n",
    "print(f\"\\nüìä MEJOR SCORE (CV): {grid_search_lr.best_score_:.4f}\")\n",
    "\n",
    "# Entrenar modelo optimizado\n",
    "lr_optimized = grid_search_lr.best_estimator_\n",
    "y_pred_lr_opt = lr_optimized.predict(X_test_scaled)\n",
    "y_pred_proba_lr_opt = lr_optimized.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "# Calcular m√©tricas del modelo optimizado\n",
    "lr_opt_accuracy = accuracy_score(y_test, y_pred_lr_opt)\n",
    "lr_opt_precision = precision_score(y_test, y_pred_lr_opt)\n",
    "lr_opt_recall = recall_score(y_test, y_pred_lr_opt)\n",
    "lr_opt_f1 = f1_score(y_test, y_pred_lr_opt)\n",
    "lr_opt_auc = roc_auc_score(y_test, y_pred_proba_lr_opt)\n",
    "\n",
    "print(f\"\\nüìä RESULTADOS DEL MODELO OPTIMIZADO:\")\n",
    "print(f\"‚úÖ Accuracy:  {lr_opt_accuracy:.4f}\")\n",
    "print(f\"‚úÖ Precision: {lr_opt_precision:.4f}\")\n",
    "print(f\"‚úÖ Recall:    {lr_opt_recall:.4f}\")\n",
    "print(f\"‚úÖ F1-Score:  {lr_opt_f1:.4f}\")\n",
    "print(f\"‚úÖ AUC-ROC:   {lr_opt_auc:.4f}\")\n",
    "\n",
    "# Comparaci√≥n con modelo original\n",
    "print(f\"\\nüìà MEJORA RESPECTO AL MODELO ORIGINAL:\")\n",
    "print(f\"  ‚Ä¢ Accuracy:  {lr_opt_accuracy - lr_accuracy:+.4f}\")\n",
    "print(f\"  ‚Ä¢ Precision: {lr_opt_precision - lr_precision:+.4f}\")\n",
    "print(f\"  ‚Ä¢ Recall:    {lr_opt_recall - lr_recall:+.4f}\")\n",
    "print(f\"  ‚Ä¢ F1-Score:  {lr_opt_f1 - lr_f1:+.4f}\")\n",
    "print(f\"  ‚Ä¢ AUC-ROC:   {lr_opt_auc - lr_auc:+.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e998287",
   "metadata": {},
   "source": [
    "## 13. Evaluaci√≥n y Comparaci√≥n Final de Modelos\n",
    "\n",
    "Comparamos todos los modelos entrenados y seleccionamos el mejor para despliegue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4457c43e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EVALUACI√ìN Y COMPARACI√ìN FINAL DE MODELOS\n",
    "print(\"üèÜ EVALUACI√ìN Y COMPARACI√ìN FINAL DE MODELOS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Crear tabla comparativa de resultados\n",
    "results_comparison = pd.DataFrame({\n",
    "    'Modelo': ['Regresi√≥n Log√≠stica', 'k-NN', 'Random Forest', 'LR Optimizada'],\n",
    "    'Accuracy': [lr_accuracy, knn_accuracy, rf_accuracy, lr_opt_accuracy],\n",
    "    'Precision': [lr_precision, knn_precision, rf_precision, lr_opt_precision],\n",
    "    'Recall': [lr_recall, knn_recall, rf_recall, lr_opt_recall],\n",
    "    'F1-Score': [lr_f1, knn_f1, rf_f1, lr_opt_f1],\n",
    "    'AUC-ROC': [lr_auc, knn_auc, rf_auc, lr_opt_auc]\n",
    "})\n",
    "\n",
    "print(\"üìä TABLA COMPARATIVA DE RESULTADOS:\")\n",
    "display(results_comparison.round(4))\n",
    "\n",
    "# Visualizaci√≥n comparativa\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "# Gr√°fico de barras para todas las m√©tricas\n",
    "metrics = ['Accuracy', 'Precision', 'Recall', 'F1-Score', 'AUC-ROC']\n",
    "colors = ['skyblue', 'lightgreen', 'lightcoral', 'gold', 'lightpink']\n",
    "\n",
    "for i, metric in enumerate(metrics):\n",
    "    ax = axes[i//3, i%2] if i < 4 else None\n",
    "    if ax is not None:\n",
    "        ax.bar(results_comparison['Modelo'], results_comparison[metric], \n",
    "               color=colors[i], alpha=0.7, edgecolor='black')\n",
    "        ax.set_title(f'Comparaci√≥n - {metric}', fontsize=12)\n",
    "        ax.set_ylabel(metric)\n",
    "        ax.tick_params(axis='x', rotation=45)\n",
    "        ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Gr√°fico radar en el √∫ltimo subplot\n",
    "ax_radar = axes[1, 1]\n",
    "angles = np.linspace(0, 2*np.pi, len(metrics), endpoint=False).tolist()\n",
    "angles += angles[:1]  # Completar el c√≠rculo\n",
    "\n",
    "# Preparar datos para cada modelo\n",
    "models_radar_data = []\n",
    "for idx, row in results_comparison.iterrows():\n",
    "    values = [row[metric] for metric in metrics]\n",
    "    values += values[:1]  # Completar el c√≠rculo\n",
    "    models_radar_data.append(values)\n",
    "\n",
    "ax_radar.clear()\n",
    "for i, (model, values) in enumerate(zip(results_comparison['Modelo'], models_radar_data)):\n",
    "    ax_radar.plot(angles, values, 'o-', linewidth=2, label=model)\n",
    "    ax_radar.fill(angles, values, alpha=0.1)\n",
    "\n",
    "ax_radar.set_xticks(angles[:-1])\n",
    "ax_radar.set_xticklabels(metrics)\n",
    "ax_radar.set_ylim(0, 1)\n",
    "ax_radar.set_title('Comparaci√≥n Radar - Todas las M√©tricas', fontsize=12)\n",
    "ax_radar.legend(loc='upper right', bbox_to_anchor=(1.3, 1.0))\n",
    "ax_radar.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Seleccionar el mejor modelo\n",
    "best_model_idx = results_comparison['F1-Score'].idxmax()\n",
    "best_model_name = results_comparison.loc[best_model_idx, 'Modelo']\n",
    "best_f1_score = results_comparison.loc[best_model_idx, 'F1-Score']\n",
    "\n",
    "print(f\"\\nü•á MEJOR MODELO SELECCIONADO: {best_model_name}\")\n",
    "print(f\"üìä F1-Score: {best_f1_score:.4f}\")\n",
    "\n",
    "print(f\"\\nüí° JUSTIFICACI√ìN DE LA ELECCI√ìN:\")\n",
    "if best_model_name == 'Random Forest':\n",
    "    print(\"‚Ä¢ Random Forest obtiene el mejor balance entre precision y recall\")\n",
    "    print(\"‚Ä¢ Proporciona informaci√≥n sobre importancia de caracter√≠sticas\")\n",
    "    print(\"‚Ä¢ Es robusto ante overfitting con el ensemble de √°rboles\")\n",
    "    best_final_model = rf_model\n",
    "elif best_model_name == 'LR Optimizada':\n",
    "    print(\"‚Ä¢ La Regresi√≥n Log√≠stica optimizada mejora significativamente\")\n",
    "    print(\"‚Ä¢ Es interpretable y eficiente computacionalmente\")\n",
    "    print(\"‚Ä¢ Tiene buen rendimiento con hiperpar√°metros optimizados\")\n",
    "    best_final_model = lr_optimized\n",
    "elif best_model_name == 'k-NN':\n",
    "    print(\"‚Ä¢ k-NN obtiene excelente rendimiento para este dataset\")\n",
    "    print(\"‚Ä¢ Es simple y efectivo para problemas de clasificaci√≥n\")\n",
    "    print(\"‚Ä¢ No requiere suposiciones sobre la distribuci√≥n de datos\")\n",
    "    best_final_model = knn_model\n",
    "else:\n",
    "    print(\"‚Ä¢ Regresi√≥n Log√≠stica b√°sica ofrece buen rendimiento\")\n",
    "    print(\"‚Ä¢ Es interpretable y r√°pida de entrenar\")\n",
    "    print(\"‚Ä¢ Proporciona probabilidades calibradas\")\n",
    "    best_final_model = lr_model\n",
    "\n",
    "print(f\"\\n‚úÖ Modelo seleccionado listo para despliegue\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69a7418f",
   "metadata": {},
   "source": [
    "## 14. Persistencia del Modelo y Preprocesador\n",
    "\n",
    "Guardamos el mejor modelo y los objetos de preprocesamiento para uso futuro en la aplicaci√≥n web."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d917808",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PERSISTENCIA DEL MODELO Y PREPROCESADOR\n",
    "print(\"üíæ GUARDANDO MODELO Y PREPROCESADORES\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "import joblib\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "# Crear carpeta para modelos si no existe\n",
    "models_dir = 'models'\n",
    "os.makedirs(models_dir, exist_ok=True)\n",
    "\n",
    "# Guardar el mejor modelo\n",
    "model_filename = f'{models_dir}/best_lung_cancer_model.joblib'\n",
    "joblib.dump(best_final_model, model_filename)\n",
    "print(f\"‚úÖ Modelo guardado: {model_filename}\")\n",
    "\n",
    "# Guardar el scaler\n",
    "scaler_filename = f'{models_dir}/scaler.joblib'\n",
    "joblib.dump(scaler, scaler_filename)\n",
    "print(f\"‚úÖ Scaler guardado: {scaler_filename}\")\n",
    "\n",
    "# Guardar los label encoders\n",
    "encoders_filename = f'{models_dir}/label_encoders.joblib'\n",
    "joblib.dump(label_encoders, encoders_filename)\n",
    "print(f\"‚úÖ Label encoders guardados: {encoders_filename}\")\n",
    "\n",
    "# Guardar informaci√≥n del modelo\n",
    "model_info = {\n",
    "    'model_name': best_model_name,\n",
    "    'model_type': type(best_final_model).__name__,\n",
    "    'accuracy': results_comparison.loc[best_model_idx, 'Accuracy'],\n",
    "    'precision': results_comparison.loc[best_model_idx, 'Precision'],\n",
    "    'recall': results_comparison.loc[best_model_idx, 'Recall'],\n",
    "    'f1_score': results_comparison.loc[best_model_idx, 'F1-Score'],\n",
    "    'auc_roc': results_comparison.loc[best_model_idx, 'AUC-ROC'],\n",
    "    'feature_names': X.columns.tolist(),\n",
    "    'target_classes': label_encoders['LUNG_CANCER'].classes_.tolist()\n",
    "}\n",
    "\n",
    "info_filename = f'{models_dir}/model_info.joblib'\n",
    "joblib.dump(model_info, info_filename)\n",
    "print(f\"‚úÖ Informaci√≥n del modelo guardada: {info_filename}\")\n",
    "\n",
    "print(f\"\\nüìÅ ARCHIVOS GENERADOS EN LA CARPETA '{models_dir}':\")\n",
    "for file in os.listdir(models_dir):\n",
    "    print(f\"  ‚Ä¢ {file}\")\n",
    "\n",
    "print(f\"\\nüöÄ MODELO LISTO PARA DESPLIEGUE\")\n",
    "print(f\"   Modelo: {best_model_name}\")\n",
    "print(f\"   Rendimiento: F1-Score = {best_f1_score:.4f}\")\n",
    "\n",
    "# Funci√≥n de predicci√≥n para usar en la aplicaci√≥n web\n",
    "def predict_lung_cancer(gender, age, smoking, yellow_fingers, anxiety, \n",
    "                       peer_pressure, chronic_disease, fatigue, allergy, \n",
    "                       wheezing, alcohol_consuming, coughing, \n",
    "                       shortness_of_breath, swallowing_difficulty, chest_pain):\n",
    "    \"\"\"\n",
    "    Funci√≥n para hacer predicciones de c√°ncer de pulm√≥n\n",
    "    \"\"\"\n",
    "    # Crear array con los datos de entrada\n",
    "    input_data = np.array([[gender, age, smoking, yellow_fingers, anxiety,\n",
    "                           peer_pressure, chronic_disease, fatigue, allergy,\n",
    "                           wheezing, alcohol_consuming, coughing,\n",
    "                           shortness_of_breath, swallowing_difficulty, chest_pain]])\n",
    "    \n",
    "    # Aplicar escalado\n",
    "    input_scaled = scaler.transform(input_data)\n",
    "    \n",
    "    # Hacer predicci√≥n\n",
    "    prediction = best_final_model.predict(input_scaled)[0]\n",
    "    probability = best_final_model.predict_proba(input_scaled)[0]\n",
    "    \n",
    "    return prediction, probability\n",
    "\n",
    "print(f\"\\n‚úÖ Funci√≥n de predicci√≥n creada y lista para usar\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97b1ff51",
   "metadata": {},
   "source": [
    "## 15. Conclusiones y Pr√≥ximos Pasos\n",
    "\n",
    "### Resumen del Proyecto\n",
    "\n",
    "En este proyecto hemos implementado un sistema completo de Machine Learning para la predicci√≥n de c√°ncer de pulm√≥n:\n",
    "\n",
    "#### ‚úÖ **An√°lisis Exploratorio de Datos (EDA)**\n",
    "- Dataset con 311 muestras y 16 caracter√≠sticas\n",
    "- No se encontraron valores faltantes\n",
    "- Variables principalmente categ√≥ricas codificadas num√©ricamente\n",
    "- Balance de clases aceptable para clasificaci√≥n\n",
    "\n",
    "#### ‚úÖ **Preprocesamiento**\n",
    "- **Codificaci√≥n**: Label Encoding para variables categ√≥ricas\n",
    "- **Escalado**: StandardScaler para normalizar caracter√≠sticas\n",
    "- **Divisi√≥n**: 80% entrenamiento, 20% prueba con estratificaci√≥n\n",
    "\n",
    "#### ‚úÖ **Modelos Implementados**\n",
    "1. **Regresi√≥n Log√≠stica**: Modelo base interpretable\n",
    "2. **k-NN**: Modelo basado en vecinos cercanos  \n",
    "3. **Random Forest**: Modelo ensemble (bonificaci√≥n)\n",
    "4. **Regresi√≥n Log√≠stica Optimizada**: Con ajuste de hiperpar√°metros\n",
    "\n",
    "#### ‚úÖ **Resultados Obtenidos**\n",
    "- Todos los modelos obtuvieron excelente rendimiento (>90% accuracy)\n",
    "- El mejor modelo fue seleccionado basado en F1-Score\n",
    "- Modelos guardados y listos para despliegue\n",
    "\n",
    "#### üöÄ **Pr√≥ximos Pasos**\n",
    "1. **Desarrollo de aplicaci√≥n web con Streamlit**\n",
    "2. **Interfaz intuitiva para predicciones**\n",
    "3. **Validaci√≥n adicional con m√°s datos**\n",
    "4. **Monitoreo del modelo en producci√≥n**\n",
    "\n",
    "### üìä **Archivos Generados**\n",
    "- `models/best_lung_cancer_model.joblib`: Mejor modelo entrenado\n",
    "- `models/scaler.joblib`: Preprocesador para escalado\n",
    "- `models/label_encoders.joblib`: Codificadores de variables categ√≥ricas\n",
    "- `models/model_info.joblib`: Informaci√≥n y metadatos del modelo\n",
    "\n",
    "El proyecto est√° listo para la **Parte 2: Despliegue Web** con Streamlit."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
